


Loading a Mistral-7B model

Applying LoRA (efficient fine-tuning)

Preparing a chat dataset in the right format

Using SFTTrainer to fine-tune the model

Saving it in GGUF format for fast deployment (e.g. with llama.cpp)

